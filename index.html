<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Dip-NeRF: Depth-Based Anti-Aliased Neural Radiance Fields">
  <meta name="keywords" content="Dip-NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Dip-NeRF: Depth-Based Anti-Aliased Neural Radiance Fields</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="css/bootstrap.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/icon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <script src="./static/js/video_comparison.js"></script>

  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
</script>        
  
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
});
</script>

</head>
<body>

<section class="hero">
  <div class="hero-body", style="padding-bottom: 0rem;">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Dip-NeRF: Depth-Based Anti-Aliased Neural Radiance Fields</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Shihao Qin<sup>1,2</sup>&nbsp;&nbsp;</span>
            <span class="author-block">
              Jiangjian Xiao<sup>2</sup>&nbsp;&nbsp;</span>
            <span class="author-block">
               Jianfei Ge<sup>2*</sup>&nbsp;&nbsp;</span>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block", style="color:#726f6f"><sup>1</sup>
Faculty of Electrical Engineering and Computer Science, Ningbo University&nbsp;&nbsp;&nbsp;</span>
            <span class="author-block", style="color:#726f6f"><sup>2</sup>
Ningbo Institute of Industrial Technology, Chinese Academy of Sciences&nbsp;&nbsp;&nbsp;&nbsp;</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block", style="font-size: 15px;color:#726f6f"><sup>*&nbsp;</sup>Corresponding author&nbsp;&nbsp;&nbsp;&nbsp;</span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block", style="color:#367DBD";>Electronics 2024</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://doi.org/10.3390/electronics13081527"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="#"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Soon)</span>
                  </a>
              </span> -->
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<style>  .center-container {
    display: flex;
    justify-content: center;
  }
</style>

<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-building">
          <video poster="" id="building" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/pointcloud.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</div>
</section>


  
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>

        <img alt="Architecture" src="./static/images/Overall Framework.png" width="100%"/>

      </div>
    </div>
    <div class="content has-text-justified">
      <p>
        Neural radiation field (NeRF)-based novel view synthesis methods are gaining popularity for their ability to generate detailed and realistic images. However, most NeRF-based methods only use images to learn scene representations, ignoring the importance of depth information. The Zip-NeRF method has achieved impressive results in unbounded scenes by combining anti-aliasing techniques and mesh representations. However, the method requires a large number of input images and may perform poorly in complex scenes. Our method incorporates the advantages of Zip-NeRF and incorporates depth information to reduce the number of required images and solve the scale-free problem in borderless scenes. Experimental results show that our method effectively reduces the training time.And we can generate high-quality images and fine point cloud models using few images, even in complex scenes with numerous occlusions.
      </p>
    </div>
<!--    --><div class="center-container">
  <!-- 居中显示的图片 -->
  <img alt="Motivation" src="./static/images/Data Preprocessing.png" width="70%"/>
    <img alt="Motivation" src="./static/images/Point Cloud Generation.png" width="30%"/>
</div>
  </section>



<section class="section">
  <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
      <h2 class="title is-3">Comparison</h2>
        <!--    --><div class="center-container">
  <!-- 居中显示的图片 -->
  <img alt="Motivation" src="./static/images/Comparative Experimental.png" width="75%"/>
</div>
        <!--    --><div class="center-container">
  <!-- 居中显示的图片 -->
  <img alt="Motivation" src="./static/images/Comparative Experimental Table.png" width="75%"/>
</div>
    </div>
  </div>
</div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3">Ablation Studying</h2>
      <!--    --><div class="center-container">
  <!-- 居中显示的图片 -->
  <img alt="Motivation" src="./static/images/Ablation Experiments.png" width="100%"/>
</div>
      <!--    --><div class="center-container">
  <!-- 居中显示的图片 -->
  <img alt="Motivation" src="./static/images/Ablation Experiments Table.png" width="100%"/>
</div>
      </div>
    </div>
    <div class="content has-text-justified">
      <p>
        The ablation study clearly shows that the omission of dynamic sampling and depth loss leads to significant blurring and ghosting. Additionally, the lack of dynamic sampling methods results in a large number of invalid samples, which significantly impacts convergence speed and hinders the generation of high-quality rendered images within a short period. And, the absence of depth loss causes a focus solely on image information, disregarding depth information that could serve as a constraint. Furthermore, utilising a simple depth loss function without incorporating feature weights can result in indistinct occlusions near occluded objects and loss of detail due to the overbearing influence of depth information. As a result, it is imperative to differentiate the reliability of depth information in various regions by incorporating feature weights. Additionally, neglecting dynamic sampling methods increases the distance between sampling points and affects the convergence of the model. This can also make it difficult to accurately estimate the surface location of objects, resulting in blurred rendered images and the appearance of airborne floaters in the scene. If feature weights weighted according to depth loss are not used, some details may become blurred due to a possible lack of accurate depth information. Additionally, smoothed regions that should be more dependent on depth information may have uneven colours due to the excessive influence of the image.
      </p>
  </div>
</div>
</section>

<style>
  .image-with-label {
    display: inline-block;
    position: relative;
    margin-right: -40px;
  }

  .image-with-label .label {
    position: absolute;
    top: 0;
    left: 0;
    font-size: 0.8em;
    line-height: 1;
    color: #666;
  }
</style>



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{qin2024dipnerf,
  title={Dip-NeRF: Depth-Based Anti-Aliased Neural Radiance Fields},
  author={Qin, Shihao and Xiao, Jiangjian and Ge, Jianfei},
  journal={Electronics},
  year={2024},
  publisher={MDPI}
}</code></pre>
  </div>
</section>


<script>
  document.addEventListener('DOMContentLoaded', function () {
    document.querySelectorAll('.video-compare-container').forEach(function (container, index) {
      console.log("Index of the container:", index);
      container.addEventListener('click', function () {
        if (index === 0) {
          this.classList.toggle('expand-right');
        } else if (index === 2) {
          this.classList.toggle('expand-left');
        } else {
          this.classList.toggle('expanded');
        }
      });
    });
  });
</script>

</body>
</html>
